{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### This code is based on \"CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems\" by [\"Mohammadmehdi Naghiaei, Hossein A. Rahmani, and Yashar Deldjoo\"], available at: [rahmanidashti/CPFairRecSys: Official Codes](https://github.com/rahmanidashti/CPFairRecSys). \n",
    "\n",
    "Some parts of this code (functions, parameters, algorithms) are taken directly from the original work. Additional modifications, new functions, and changes have been made by Reza Shafiloo as part of this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvyNDFQm8Tr5"
   },
   "source": "## Install Recommendation library"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VnNvYkBmRz-F",
    "outputId": "f90d7bc2-ee33-4e90-c30d-685cb6cf7f24"
   },
   "source": "! pip install cornac",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gT5oYyYy-X8"
   },
   "source": "## Import packages"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N3KNp45j7IGM"
   },
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import product\n",
    "from sys import stdout as out\n",
    "\n",
    "import pandas as pd\n",
    "import ast  # Safely evaluate string to dictionary if necessary\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math\n",
    "from ast import literal_eval\n",
    "\n",
    "import cornac\n",
    "from cornac.eval_methods import BaseMethod, RatioSplit\n",
    "from cornac.models import MostPop, UserKNN, ItemKNN, MF, PMF, BPR, NeuMF, WMF, HPF, CVAE, VAECF, NMF\n",
    "from cornac.metrics import Precision, Recall, NDCG, AUC, MAP, FMeasure, MRR\n",
    "from cornac.data import Reader\n",
    "from cornac.utils import cache"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OEbK4PzX9ul"
   },
   "source": "## Configuration "
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6xGcL4Gm7KhT"
   },
   "source": [
    "# dataset congfig\n",
    "ds_names = [\"Food\"]\n",
    "ds_users = ['005']\n",
    "ds_items = ['020']\n",
    "\n",
    "###\n",
    "no_user_groups = 2\n",
    "no_item_groups = 2\n",
    "topk = 50  # this is not a length of recommendation ist, it is only the first topk items for the optimisation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVnSrbN9ygDF"
   },
   "source": [
    "## Load `Cornac` data and model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dcckaEz-7SQr"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# reading the train, test, and val sets\n",
    "def read_data(dataset):\n",
    "    \"\"\"\n",
    "    Read the train, test, and tune file using Cornac reader class\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : the name of the dataset\n",
    "      example: 'MovieLens100K'\n",
    "  \n",
    "    Returns\n",
    "    ----------\n",
    "    train_data:\n",
    "      The train set that is 70% of interactions\n",
    "    tune_data:\n",
    "      The tune set that is 10% of interactions\n",
    "    test_data:\n",
    "      The test set that is 20% of interactions\n",
    "    \"\"\"\n",
    "    reader = Reader()\n",
    "    train_data = reader.read(fpath=f\"datasets/{dataset}/{dataset}_train.txt\", fmt='UIR', sep='\\t')\n",
    "    tune_data = reader.read(fpath=f\"datasets/{dataset}/{dataset}_tune.txt\", fmt='UIR', sep='\\t')\n",
    "    test_data = reader.read(fpath=f\"datasets/{dataset}/{dataset}_test.txt\", fmt='UIR', sep='\\t')\n",
    "    return train_data, tune_data, test_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JxijedzS7VHq"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# load data into Cornac evaluation method\n",
    "def load_data(train_data, test_data):\n",
    "    \"\"\"\n",
    "    load data into Cornac evaluation method\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data:\n",
    "      train_data from Reader Class\n",
    "    test_data:\n",
    "      test_data from Reader Class\n",
    "  \n",
    "    Returns\n",
    "    ----------\n",
    "    eval_method:\n",
    "      Instantiation of a Base evaluation method using the provided train and test sets\n",
    "    \"\"\"\n",
    "    # exclude_unknowns (bool, default: False) – Whether to exclude unknown users/items in evaluation.\n",
    "    # Instantiate a Base evaluation method using the provided train and test sets\n",
    "    eval_method = BaseMethod.from_splits(\n",
    "        train_data=train_data, test_data=test_data, rating_threshold=5, exclude_unknowns=True, verbose=True\n",
    "    )\n",
    "\n",
    "    return eval_method"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "code",
    "id": "gtOdLiJ67XiZ"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# running the cornac\n",
    "def run_model(eval_method):\n",
    "    \"\"\"\n",
    "    running the cornac\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_method:\n",
    "      Cornac's evaluation protocol\n",
    "  \n",
    "    Returns\n",
    "    ----------\n",
    "    exp:\n",
    "      Cornac's Experiment\n",
    "    \"\"\"\n",
    "\n",
    "    models = [\n",
    "        # MostPop(),\n",
    "        # UserKNN(k=20, similarity=\"cosine\", weighting=\"bm25\", name=\"UserKNN-BM25\"),\n",
    "        # ItemKNN(k=20, similarity=\"cosine\", name=\"ItemKNN-Cosine\"),\n",
    "        # BPR(k=50, max_iter=200, learning_rate=0.001, lambda_reg=0.001, verbose=True),\n",
    "        # WMF(k=50, max_iter=50, learning_rate=0.001, lambda_u=0.01, lambda_v=0.01, verbose=True, seed=123),\n",
    "        # HPF(k=50, seed=123, hierarchical=False, name=\"PF\"),\n",
    "        VAECF(k=10, autoencoder_structure=[20], act_fn=\"tanh\", likelihood=\"mult\", n_epochs=100, batch_size=100,\n",
    "              learning_rate=0.001, beta=1.0, seed=123, use_gpu=True, verbose=False),\n",
    "        # NeuMF(num_factors=9, layers=[32, 16, 8], act_fn=\"tanh\", num_epochs=5, num_neg=3, batch_size=256, lr=0.001, seed=42, verbose=True)\n",
    "    ]\n",
    "\n",
    "    # define metrics to evaluate the models\n",
    "    metrics = [\n",
    "        AUC(), MAP(), MRR(), NDCG(k=10), Recall(k=10)\n",
    "        # Precision(k=5), Precision(k=10), Precision(k=20),  Precision(k=50),\n",
    "        # Recall(k=5), Recall(k=10), Recall(k=20), Recall(k=50),\n",
    "        # FMeasure(k=5), FMeasure(k=10), FMeasure(k=20), FMeasure(k=50),\n",
    "        # NDCG(k=5), NDCG(k=10), NDCG(k=20), NDCG(k=50)\n",
    "    ]\n",
    "\n",
    "    # put it together in an experiment, voilà!\n",
    "    exp = cornac.Experiment(eval_method=eval_method, models=models, metrics=metrics)\n",
    "    exp.run()\n",
    "\n",
    "    return exp"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKk0B-6wzEhj"
   },
   "source": [
    "\n",
    "## Load user and item groups"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TmAJmsuu9nIY"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# Create a set of IDs for each users group\n",
    "# Creat a matrix U which shows the user and the groups of the user\n",
    "def read_user_groups(user_group_fpath: str, gid) -> set:\n",
    "    \"\"\"\n",
    "    Read the user groups lists\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    user_group_fpath:\n",
    "      The path of the user group file\n",
    "  \n",
    "    U (global variabvle):\n",
    "      The global matrix of users and their group\n",
    "  \n",
    "    Returns\n",
    "    ----------\n",
    "    user_ids:\n",
    "      The set of user ids corresponding to the group\n",
    "    \"\"\"\n",
    "\n",
    "    user_group = open(user_group_fpath, 'r').readlines()\n",
    "    user_ids = set()\n",
    "    for eachline in user_group:\n",
    "        uid = eachline.strip()\n",
    "        # convert uids to uidx\n",
    "        uid = eval_method.train_set.uid_map[uid]\n",
    "        uid = int(uid)\n",
    "        user_ids.add(uid)\n",
    "        U[uid][gid] = 1\n",
    "    return user_ids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wQIgU-RFN9a0"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# read test data\n",
    "def read_ground_truth(test_file):\n",
    "    \"\"\"\n",
    "    Read test set data\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_file:\n",
    "      The test set data\n",
    "  \n",
    "    Returns\n",
    "    ----------\n",
    "    ground_truth:\n",
    "      A dictionary includes user with actual items in test data\n",
    "    \"\"\"\n",
    "    ground_truth = defaultdict(set)\n",
    "    truth_data = open(test_file, 'r').readlines()\n",
    "    for eachline in truth_data:\n",
    "        uid, iid, _ = eachline.strip().split()\n",
    "\n",
    "        # convert uids to uidx\n",
    "        uid = eval_method.train_set.uid_map[uid]\n",
    "        # convert iids to iidx\n",
    "        iid = eval_method.train_set.iid_map[iid]\n",
    "\n",
    "        uid, iid = int(uid), int(iid)\n",
    "        ground_truth[uid].add(iid)\n",
    "\n",
    "    return ground_truth"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YuxZe64gNejy"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# read train data\n",
    "def read_train_data(train_file):\n",
    "    \"\"\"\n",
    "    Read test set data\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_file:\n",
    "      The train_file set data\n",
    "  \n",
    "    Returns\n",
    "    ----------\n",
    "    train_checkins:\n",
    "      A dictionary includes user with items in train data\n",
    "    pop: dictionary\n",
    "      A dictionary of all items alongside of its occurrences counter in the training data\n",
    "      example: {1198: 893, 1270: 876, 593: 876, 2762: 867}\n",
    "    \"\"\"\n",
    "    train_checkins = defaultdict(set)\n",
    "    pop_items = dict()\n",
    "    train_data = open(train_file, 'r').readlines()\n",
    "\n",
    "    for eachline in train_data:\n",
    "        uid, iid, _ = eachline.strip().split()\n",
    "        print(eachline.strip().split())\n",
    "        # convert uids to uidx\n",
    "        uid = eval_method.train_set.uid_map[uid]\n",
    "        # convert iids to iidx\n",
    "        iid = eval_method.train_set.iid_map[iid]\n",
    "\n",
    "        uid, iid = int(uid), int(iid)\n",
    "        # a dictionary of popularity of items\n",
    "        if iid in pop_items.keys():\n",
    "            pop_items[iid] += 1\n",
    "        else:\n",
    "            pop_items[iid] = 1\n",
    "        train_checkins[uid].add(iid)\n",
    "    return train_checkins, pop_items"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vU5YS_gv6SO"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uI3kZR7Bn4EJ"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def catalog_coverage(predicted: list, catalog: list) -> float:\n",
    "    \"\"\"\n",
    "    Computes the catalog coverage for k lists of recommendations\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted : a list of lists\n",
    "        Ordered predictions\n",
    "        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "    catalog: list\n",
    "        A list of all unique items in the training data\n",
    "        example: ['A', 'B', 'C', 'X', 'Y', Z]\n",
    "    k: integer\n",
    "        The number of observed recommendation lists\n",
    "        which randomly choosed in our offline setup\n",
    "    Returns\n",
    "    ----------\n",
    "    catalog_coverage:\n",
    "        The catalog coverage of the recommendations as a percent rounded to 2 decimal places\n",
    "    ----------\n",
    "    Metric Defintion:\n",
    "    Ge, M., Delgado-Battenfeld, C., & Jannach, D. (2010, September).\n",
    "    Beyond accuracy: evaluating recommender systems by coverage and serendipity.\n",
    "    In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). ACM.\n",
    "    \"\"\"\n",
    "    predicted_flattened = [p for sublist in predicted for p in sublist]\n",
    "    L_predictions = len(set(predicted_flattened))\n",
    "    # print(\"L_predictions:\",L_predictions)\n",
    "    # print(\"len(catalog):\",len(catalog))\n",
    "    catalog_coverage = round(L_predictions / (len(catalog) * 1.0) * 100, 2)\n",
    "    # output: precent (%)\n",
    "    return catalog_coverage"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T451FOM3m4qx"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def novelty(predicted: list, pop: dict, u: int, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Computes the novelty for a list of recommended items for a user\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted : a list of recommedned items\n",
    "        Ordered predictions\n",
    "        example: ['X', 'Y', 'Z']\n",
    "    pop: dictionary\n",
    "        A dictionary of all items alongside of its occurrences counter in the training data\n",
    "        example: {1198: 893, 1270: 876, 593: 876, 2762: 867}\n",
    "    u: integer\n",
    "        The number of users in the training data\n",
    "    k: integer\n",
    "        The length of recommended lists per user\n",
    "    Returns\n",
    "    ----------\n",
    "    novelty:\n",
    "        The novelty of the recommendations in system level\n",
    "    mean_self_information:\n",
    "        The novelty of the recommendations in recommended top-N list level\n",
    "    ----------\n",
    "    Metric Defintion:\n",
    "    Zhou, T., Kuscsik, Z., Liu, J. G., Medo, M., Wakeling, J. R., & Zhang, Y. C. (2010).\n",
    "    Solving the apparent diversity-accuracy dilemma of recommender systems.\n",
    "    Proceedings of the National Academy of Sciences, 107(10), 4511-4515.\n",
    "    \"\"\"\n",
    "    self_information = 0\n",
    "    for item in predicted:\n",
    "        if item in pop.keys():\n",
    "            item_popularity = pop[item] / u\n",
    "            item_novelty_value = np.sum(-np.log2(item_popularity))\n",
    "        else:\n",
    "            item_novelty_value = 0\n",
    "        self_information += item_novelty_value\n",
    "    novelty_score = self_information / k\n",
    "    return novelty_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f7Ymn9W4Qdht"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def precisionk(actual, predicted):\n",
    "    return 1.0 * len(set(actual) & set(predicted)) / len(predicted)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WR8y_5vrKKaw"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def recallk(actual, predicted):\n",
    "    return 1.0 * len(set(actual) & set(predicted)) / len(actual)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VTs77lfzLMBx"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def ndcgk(actual, predicted):\n",
    "    idcg = 1.0\n",
    "    dcg = 1.0 if predicted[0] in actual else 0.0\n",
    "    for i, p in enumerate(predicted[1:]):\n",
    "        if p in actual:\n",
    "            dcg += 1.0 / np.log(i + 2)\n",
    "        idcg += 1.0 / np.log(i + 2)\n",
    "    return dcg / idcg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbchhQqfwEBg"
   },
   "source": [
    "## Load User and Item Matrices"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_YBJA3fayetN"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "\n",
    "# Here we saved the results of scores and you can read them from repo to do your experiments.\n",
    "# S is a matrix to store user's scores on each item\n",
    "# P incldues the indecies of topk ranked items\n",
    "# Sprime saves the scores of topk ranked items\n",
    "\n",
    "def load_ranking_matrices(model, total_users, total_items, topk):\n",
    "    S = np.zeros((total_users, total_items))\n",
    "    P = np.zeros((total_users, topk))\n",
    "    \n",
    "    print(model.name)\n",
    "    for uid in tqdm(range(total_users)):\n",
    "        S[uid] = model.score(uid)\n",
    "        P[uid] = np.array(list(reversed(model.score(uid).argsort()))[:topk])\n",
    "\n",
    "\n",
    "    return S, P"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6purGS8lSc0W"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# Ahelp is a binary matrix in which an element of its is 1 if the corresponding element in P (which is an item index) is in ground truth.\n",
    "# Actually is shows whether the rankied item in P is included in ground truth or not.\n",
    "\n",
    "def load_ground_truth_index(total_users, topk, P, train_checkins):\n",
    "    Ahelp = np.zeros((total_users, topk))\n",
    "    for uid in tqdm(range(total_users)):\n",
    "        for j in range(topk):\n",
    "            # convert user_ids to user_idx\n",
    "            # convert item_ids to item_idx\n",
    "            if P[uid][j] in train_checkins[uid]:\n",
    "                Ahelp[uid][j] = 1\n",
    "    return Ahelp"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VuOUY4lCJ57A"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "# create a set of IDs for each users group\n",
    "def read_item_groups(item_group_fpath: str, gid) -> set:\n",
    "    item_group = open(item_group_fpath, 'r').readlines()\n",
    "    item_ids = set()\n",
    "    for eachline in item_group:\n",
    "        iid = eachline.strip()\n",
    "        # convert iids to iidx\n",
    "        iid = eval_method.train_set.iid_map[iid]\n",
    "        iid = int(iid)\n",
    "        item_ids.add(iid)\n",
    "        I[iid][gid] = 1\n",
    "    return item_ids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HRlw5kZLPzQ4"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def read_item_index(total_users, topk, no_item_groups):\n",
    "    Ihelp = np.zeros((total_users, topk, no_item_groups))\n",
    "    for uid in range(total_users):\n",
    "        for lid in range(topk):\n",
    "            # convert item_ids to item_idx\n",
    "            if P[uid][lid] in shorthead_item_ids:\n",
    "                Ihelp[uid][lid][0] = 1\n",
    "            elif P[uid][lid] in longtail_item_ids:\n",
    "                Ihelp[uid][lid][1] = 1\n",
    "    return Ihelp"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# New script  created by Reza Shafiloo\n",
    "# This script loads user training data and item metadata, merges them, and processes the merged data to \n",
    "# count item ratings for each provider. It then aggregates these counts into a provider-level inventory \n",
    "# represented as dictionaries and adds this information back into the item metadata DataFrame.\n",
    "# Finally, it converts the inventory data between string and dictionary formats for further processing.\n",
    "# Loading the data\n",
    "TrainingData = pd.read_csv('datasets/'+ds_names[0]+'/'+ds_names[0]+'_train.txt', sep=\"\\t\",\n",
    "                           names=[\"User-ID\", \"IID\", \"Rating\"], index_col=False,\n",
    "                           encoding=\"unicode-escape\", on_bad_lines='skip')\n",
    "\n",
    "itemMeta = pd.read_csv('datasets/'+ds_names[0]+'/'+ds_names[0]+'_meta.txt', sep=\"\\t\",\n",
    "                       names=[\"IID\", \"Provider\"], index_col=False,\n",
    "                       encoding=\"unicode-escape\", on_bad_lines='skip')\n",
    "\n",
    "# Merge TrainingData with itemMeta\n",
    "merged_data = pd.merge(TrainingData, itemMeta, on=\"IID\", how=\"left\")\n",
    "\n",
    "# Group by Provider and IID, and count ratings for each IID\n",
    "item_rating_counts = merged_data.groupby(['Provider', 'IID']).size().reset_index(name='RatingCount')\n",
    "\n",
    "# Aggregate these counts at the provider level into a dictionary (IID, RatingCount)\n",
    "providers_inventory = item_rating_counts.groupby('Provider').apply(\n",
    "    lambda x: dict(zip(x['IID'], x['RatingCount']))\n",
    ").reset_index(name='itemsAndRatings')\n",
    "\n",
    "# Add this aggregated data as a new column in itemMeta DataFrame\n",
    "itemMeta = itemMeta.merge(providers_inventory, on='Provider', how='left')\n",
    "\n",
    "# Convert the 'itemsAndRatings' column from dictionary to string representation\n",
    "itemMeta['itemsAndRatings'] = itemMeta['itemsAndRatings'].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "# Convert string representation back to dictionary using literal_eval (if needed for further processing)\n",
    "itemMeta['itemsAndRatings'] = itemMeta['itemsAndRatings'].apply(literal_eval)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkl6XrhAwQG2"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "48cabQBvwPMN"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def metric_per_group(group, W):\n",
    "    NDCG10 = list()\n",
    "    Pre10 = list()\n",
    "    Rec10 = list()\n",
    "    Novelty10 = list()\n",
    "    predicted = list()\n",
    "    All_Predicted = list()\n",
    "    for uid in tqdm(group):\n",
    "        decision_vars = [W[uid][j].x for j in W[uid]]\n",
    "        if uid in ground_truth.keys():\n",
    "            for j in range(50):\n",
    "                if W[uid][j].x == 1:\n",
    "                    predicted.append(P[uid][j])\n",
    "            copy_predicted = predicted[:]\n",
    "            All_Predicted.append(copy_predicted)\n",
    "            NDCG = ndcgk(actual=ground_truth[uid], predicted=predicted)\n",
    "            Pre = precisionk(actual=ground_truth[uid], predicted=predicted)\n",
    "            Rec = recallk(actual=ground_truth[uid], predicted=predicted)\n",
    "            Novelty = novelty(predicted=predicted, pop=pop_items, u=eval_method.total_users, k=10)\n",
    "\n",
    "            NDCG10.append(NDCG)\n",
    "            Pre10.append(Pre)\n",
    "            Rec10.append(Rec)\n",
    "            Novelty10.append(Novelty)\n",
    "\n",
    "            # cleaning the predicted list for a new user\n",
    "            predicted.clear()\n",
    "\n",
    "    catalog = catalog_coverage(predicted=All_Predicted, catalog=pop_items.keys())\n",
    "    return round(np.mean(NDCG10), 5), round(np.mean(Pre10), 5), round(np.mean(Rec10), 5), round(np.mean(Novelty10),\n",
    "                                                                                                5), catalog"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JorbXFzomfmv"
   },
   "source": [
    "# Function from Original Work by Hossein A. Rahmani rahmanidashti/CPFairRecSys: [Official Codes] CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# This function has been used without modifications.\n",
    "def metric_on_all(W):\n",
    "    predicted_user = list()\n",
    "    NDCG_all = list()\n",
    "    PRE_all = list()\n",
    "    REC_all = list()\n",
    "    Novelty_all = list()\n",
    "    All_Predicted = list()\n",
    "\n",
    "    for uid in tqdm(range(eval_method.total_users)):\n",
    "\n",
    "        if uid in ground_truth.keys():\n",
    "            for j in range(50):\n",
    "                if W[uid][j].x == 1:\n",
    "                    predicted_user.append(P[uid][j])\n",
    "            \n",
    "            copy_predicted = predicted_user[:]\n",
    "            All_Predicted.append(copy_predicted)\n",
    "\n",
    "            NDCG_user = ndcgk(actual=ground_truth[uid], predicted=predicted_user)\n",
    "            PRE_user = precisionk(actual=ground_truth[uid], predicted=predicted_user)\n",
    "            REC_user = recallk(actual=ground_truth[uid], predicted=predicted_user)\n",
    "            Novelty_user = novelty(predicted=predicted_user, pop=pop_items, u=eval_method.total_users, k=10)\n",
    "\n",
    "            NDCG_all.append(NDCG_user)\n",
    "            PRE_all.append(PRE_user)\n",
    "            REC_all.append(REC_user)\n",
    "            Novelty_all.append(Novelty_user)\n",
    "\n",
    "            # cleaning the predicted list for a new user\n",
    "            predicted_user.clear()\n",
    "\n",
    "    catalog = catalog_coverage(predicted=All_Predicted, catalog=pop_items.keys())\n",
    "    return round(np.mean(NDCG_all), 5), round(np.mean(PRE_all), 5), round(np.mean(REC_all), 5), round(\n",
    "        np.mean(Novelty_all), 5), catalog"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Optimization Functions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# New function created by Reza Shafiloo\n",
    "#  Updates the provider inventories by incrementing the count of items based on the recommendation list.\n",
    "# For each item in the recommendation list, it finds the provider that owns the item and updates the count.\n",
    "# If the item is not found in any provider's inventory, a message is printed.\n",
    "    \n",
    "def update_provider_inventory(recommendation_list):\n",
    "    for item_id in recommendation_list:\n",
    "        # Convert item_id to string if it's not already\n",
    "        item_id = item_id\n",
    "        # Iterate over the list of providers\n",
    "        found = False\n",
    "        for provider_idx, provider_dict in enumerate(providers):\n",
    "            if item_id in provider_dict:  # Check if this item belongs to the current provider's dictionary\n",
    "                provider_dict[item_id] += 1  # Increment the count of this item\n",
    "                found = True\n",
    "                \n",
    "                break  # Stop searching once the provider is found\n",
    "        if not found:\n",
    "            print(f\"Item {item_id} not found in any provider's inventory\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# New function created by Reza Shafiloo\n",
    "# Calculates the deviation from item fairness (DIF) for each item in the recommendation list.\n",
    "# It temporarily adds the item to each provider's inventory, calculates the entropy and the \n",
    "# difference from the optimal entropy (assuming a uniform distribution), and then restores \n",
    "# the inventory to its original state. The differences are stored in a list and returned.\n",
    "    \n",
    "def calculate_deviation_from_item_fairness(recommendation_list, providers):\n",
    "    DIF_list = []\n",
    "    \n",
    "\n",
    "    for item_id in recommendation_list:\n",
    "        # Iterate through each provider\n",
    "        for provider_idx, provider_dict in enumerate(providers):\n",
    "            if item_id in provider_dict:\n",
    "                # Temporarily increase the count for this item\n",
    "                provider_dict[item_id] += 1\n",
    "                # Calculate the new entropy with this item added\n",
    "                total_recommendations = sum(provider_dict.values())\n",
    "                entropy = 0\n",
    "                for count in provider_dict.values():\n",
    "                    p = count / total_recommendations\n",
    "                    entropy -= p * math.log2(p) if p > 0 else 0\n",
    "\n",
    "                # Calculate the optimal entropy (assuming uniform distribution)\n",
    "                if total_recommendations > 0:\n",
    "                    optimal_entropy = math.log2(len(provider_dict)) if len(provider_dict) > 0 else 0\n",
    "                else:\n",
    "                    optimal_entropy = 0\n",
    "\n",
    "                # Calculate the difference from optimal entropy\n",
    "                difference_from_optimal = optimal_entropy - entropy\n",
    "\n",
    "                # Store the difference for this provider\n",
    "                DIF_list.append(difference_from_optimal)\n",
    "\n",
    "                # Reset the item count to its original state\n",
    "                provider_dict[item_id] -= 1\n",
    "\n",
    "    return DIF_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# New function created by Reza Shafiloo\n",
    "# Calculates the deviation from provider fairness (DPF) for each item in the recommendation list.\n",
    "# The function temporarily updates each provider's inventory to include the item, calculates the entropy and the difference from the optimal entropy (assuming uniform distribution), and then resets the inventory to its original state. The results are stored in a list and returned.\n",
    "    \n",
    "def calculate_deviation_from_provider_fairness(recommendation_list, providers):\n",
    "    DPF_list = []\n",
    "    total_length = sum(sum(provider_dict.values()) for provider_dict in providers)\n",
    "\n",
    "    # Iterate over each item in the recommendation list\n",
    "    for item_id in recommendation_list:\n",
    "        # Convert item_id to string if it's not already\n",
    "        item_id = item_id\n",
    "\n",
    "        # Temporarily update each provider's inventory if it contains the item\n",
    "        for provider_dict in providers:\n",
    "            if item_id in provider_dict:\n",
    "                # Temporarily increase the count for this item\n",
    "                provider_dict[item_id] += 1\n",
    "\n",
    "                entropy = 0\n",
    "                for updatedInventory in providers:\n",
    "                    count = sum(updatedInventory.values())\n",
    "                    p = count / (total_length + 1)\n",
    "                    entropy -= p * math.log2(p) if p > 0 else 0\n",
    "\n",
    "                # Calculate the optimal entropy (assuming uniform distribution)\n",
    "                optimal_entropy = math.log2(len(providers)) if len(provider_dict) > 0 else 0\n",
    "\n",
    "                # Calculate the difference from optimal entropy\n",
    "                difference_from_optimal = optimal_entropy - entropy\n",
    "\n",
    "                # Store the difference for this provider\n",
    "                DPF_list.append(difference_from_optimal)\n",
    "\n",
    "                # Reset the item count to its original state\n",
    "                provider_dict[item_id] -= 1\n",
    "\n",
    "    return DPF_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# New Class created by Reza Shafiloo\n",
    "# Represents a decision variable for selecting items in the optimization process.\n",
    "# Initializes with a default value of 0, indicating that the item is not selected.\n",
    "    \n",
    "class DecisionVariable:\n",
    "    def __init__(self):\n",
    "        self.x = 0  # Initialize the decision variable as 0 (not selected)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# New function created by Reza Shafiloo\n",
    "# Optimizes the recommendation process based on the specified fairness criteria ('N', 'I', 'P', 'C', 'CI', 'CP', 'IP', 'CIP'). It adjusts item scores using different fairness measures, selects the top-k items for each user,and updates user, group, and provider metrics accordingly. The function returns the decision variables and item group metrics.\n",
    "    \n",
    "def CIP_Recommendation_optimizer(fairness='N', cepsilon=0.000005, iepsilon=0.0000005, pepsilon=0.0000005):\n",
    "    recommendations = []\n",
    "    V1 = set(range(total_users))\n",
    "    V3 = set(range(no_user_groups))  # User groups\n",
    "    V4 = set(range(no_item_groups))  # Item groups\n",
    "\n",
    "    group_dcg = {k: 0 for k in V3}\n",
    "    group_ndcg = {k: 0 for k in V3}\n",
    "    group_precision = {k: 0 for k in V3}\n",
    "    group_recall = {k: 0 for k in V3}\n",
    "\n",
    "    item_group = {k: 0 for k in V4}\n",
    "    \n",
    "    W = {uid: {j: DecisionVariable() for j in range(len(P[uid]))} for uid in range(total_users)}\n",
    "\n",
    "\n",
    "    for uid in tqdm(range(total_users), leave=False):\n",
    "\n",
    "        V2 = set(range(len(P[uid])))  # Top items for the user 'uid'\n",
    "        # W = {j: 0 for j in V2}  # Binary decision variable for each item\n",
    "        DIF = calculate_deviation_from_item_fairness(P[uid], providers)\n",
    "        DPF = calculate_deviation_from_provider_fairness(P[uid], providers)\n",
    "\n",
    "        # Set the objective function to maximize the sum of scores of selected items\n",
    "        scores = {P[uid][j]: S[uid][j] for j in V2}\n",
    "        if fairness == 'N':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] for j in V2}\n",
    "        elif fairness == 'I':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - iepsilon * DIF[j] for j in V2}\n",
    "        elif fairness == 'P':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - pepsilon * DPF[j] for j in V2}\n",
    "        elif fairness == 'C':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - cepsilon * (\n",
    "                    (group_ndcg[1] + Ahelp[uid][j] * U[uid][1]) - (group_ndcg[0] + Ahelp[uid][j] * U[uid][0])) for j\n",
    "                               in V2}\n",
    "        elif fairness == 'CI':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - cepsilon * (\n",
    "                    (group_ndcg[1] + Ahelp[uid][j] * U[uid][1]) - (group_ndcg[0] + Ahelp[uid][j] * U[uid][\n",
    "                0])) - iepsilon * DIF[j] for j in V2}\n",
    "        elif fairness == 'CP':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - cepsilon * (\n",
    "                    (group_ndcg[1] + Ahelp[uid][j] * U[uid][1]) - (group_ndcg[0] + Ahelp[uid][j] * U[uid][\n",
    "                0])) - pepsilon * DPF[j] for j in V2}\n",
    "        elif fairness == 'IP':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - iepsilon * DIF[j] - pepsilon * DPF[j] for j in V2}\n",
    "        elif fairness == 'CIP':\n",
    "            adjusted_scores = {P[uid][j]: S[uid][j] - iepsilon * DIF[j] - pepsilon * DPF[j] - cepsilon * (\n",
    "                    (group_ndcg[1] + Ahelp[uid][j] * U[uid][1]) - (group_ndcg[0] + Ahelp[uid][j] * U[uid][0])) for j\n",
    "                               in V2}\n",
    "\n",
    "        # Select the top-k items based on scores\n",
    "        selected_items = sorted(adjusted_scores, key=adjusted_scores.get, reverse=True)[:min(10, len(P[uid]))]\n",
    "        for j in range(len(P[uid])):\n",
    "            if P[uid][j] in selected_items:\n",
    "                W[uid][j].x = 1\n",
    "        # decision_vars = [W[uid][j].x for j in W[uid]]\n",
    "        k = 10\n",
    "        # Update user metrics and group metrics\n",
    "        user_dcg = sum(W[uid][j].x * Ahelp[uid][j] for j in V2)\n",
    "        user_precision = sum(W[uid][j].x * Ahelp[uid][j] for j in V2) / k\n",
    "        user_recall = sum(W[uid][j].x * (j in train_checkins[uid]) for j in V2) / len(train_checkins[uid])\n",
    "\n",
    "        # Update group metrics\n",
    "        for k in V3:\n",
    "            group_ndcg[k] += user_dcg * U[uid][k]\n",
    "            group_precision[k] += user_precision * U[uid][k]\n",
    "            group_recall[k] += user_recall * U[uid][k]\n",
    "\n",
    "        for k in V4:\n",
    "            item_group[k] += sum(W[uid][j].x * Ihelp[uid][j][k] for j in V2)\n",
    "\n",
    "        recommendations.append(selected_items)\n",
    "        update_provider_inventory(selected_items)\n",
    "    return W, item_group \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# New function created by Reza Shafiloo\n",
    "# This function imulates the update of provider inventories based on the recommendation lists generated.\n",
    "#This function works on a deep copy of the original provider inventory (PI) to ensure \n",
    "#the original data remains unchanged. It returns both the original and updated inventories.\n",
    "\n",
    "\n",
    "def simulate_inventory_update(W, PI):\n",
    "    # Work on a deep copy of the providers inventory to ensure the original remains unchanged\n",
    "    temp_PI = copy.deepcopy(PI)\n",
    "\n",
    "    updated_inventories = []  # List to store copies of updated dictionaries\n",
    "    RecLists = []  # List to store final recommendation lists\n",
    "    \n",
    "    # Generate recommendation lists based on provided data\n",
    "    for uid in tqdm(range(eval_method.total_users)):\n",
    "        if uid in ground_truth.keys():\n",
    "            filtered_item_df = itemMeta[itemMeta['iid'].isin(ground_truth[uid])]\n",
    "            mask = [int(var) for var in W[uid]]\n",
    "            \n",
    "            # Create the sublist using the converted mask\n",
    "            sublist = [item for item, m in zip(ground_truth[uid], mask) if m == 1]\n",
    "            filtered_item_df = itemMeta[itemMeta['iid'].isin(sublist)]\n",
    "            RecLists.append(filtered_item_df['iid'].tolist())\n",
    "    \n",
    "    IID_counts = {}\n",
    "    for recommendation in RecLists:\n",
    "        for IID in recommendation:\n",
    "            if IID in IID_counts:\n",
    "                IID_counts[IID] += 1\n",
    "            else:\n",
    "                IID_counts[IID] = 1\n",
    "    print(\"IID_counts:\",IID_counts)\n",
    "    # Update the copy of the provider inventory with the counts\n",
    "    for i, provider_entry in enumerate(temp_PI):\n",
    "        try:\n",
    "            if isinstance(provider_entry, str):\n",
    "                provider_dict = ast.literal_eval(provider_entry)\n",
    "            else:\n",
    "                provider_dict = provider_entry\n",
    "\n",
    "            if not isinstance(provider_dict, dict):\n",
    "                raise ValueError(\"Provider inventory entry is not a dictionary or convertible string!\")\n",
    "\n",
    "            for IID in list(provider_dict.keys()):\n",
    "                if IID in IID_counts:\n",
    "                    provider_dict[IID] = provider_dict.get(IID, 0) + IID_counts[IID]\n",
    "\n",
    "            # Store the updated dictionary back into the temporary inventory\n",
    "            temp_PI[i] = provider_dict\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing inventory entry at index {i}: {e}\")\n",
    "\n",
    "    # Return the unchanged original inventory and the updated copy\n",
    "    return PI, temp_PI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# New function created by Reza Shafiloo\n",
    "# Calculates the Gini coefficients for each provider's inventory to measure inequality.\n",
    "# The function also calculates the overall Gini coefficient for the total inventory across all providers\n",
    "#and returns the mean Gini coefficient along with individual Gini values.\n",
    "\n",
    "def calculate_gini_coefficients(inventories):\n",
    "    def gini(array):\n",
    "        \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "        from numpy import sort, mean, arange\n",
    "\n",
    "        # All values are treated equally, arrays must be 1d:\n",
    "        array = array.flatten()\n",
    "        if any(array < 0):\n",
    "            array = array[array >= 0]  # Remove negative values for calculation\n",
    "        if len(array) == 0:\n",
    "            return 0  # Return 0 if array is empty\n",
    "        array = sort(array)\n",
    "        index = arange(1, array.shape[0] + 1)\n",
    "        n = array.shape[0]\n",
    "        return ((2 * index - n - 1) * array).sum() / (n * array.sum())\n",
    "\n",
    "    gini_indices = []\n",
    "\n",
    "    # Calculate Gini index for each provider's inventory\n",
    "    for inventory in inventories:\n",
    "        if isinstance(inventory, dict):\n",
    "            values = list(inventory.values())\n",
    "            gini_index = gini(np.array(values))\n",
    "            gini_indices.append(gini_index)\n",
    "        else:\n",
    "            print(\"Inventory data is not a dictionary. Skipping...\")\n",
    "    \n",
    "    all_inventories = []\n",
    "\n",
    "    # Aggregate all inventory values into one list\n",
    "    for inventory in inventories:\n",
    "        if isinstance(inventory, dict):\n",
    "            sumValue = sum(list(inventory.values()))\n",
    "            all_inventories.append(sumValue)  # Extend the list of all inventories\n",
    "        else:\n",
    "            print(\"Inventory data is not a dictionary. Skipping...\")\n",
    "\n",
    "    # Calculate Gini index for the total inventory across all providers\n",
    "    total_gini_index = gini(np.array(all_inventories))\n",
    "\n",
    "    # Calculate and return the mean of all Gini indices\n",
    "    mean_gini_index = np.mean(gini_indices) if gini_indices else 0\n",
    "    return total_gini_index,mean_gini_index, gini_indices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9NhMbgRyIXg"
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iPtl1pdcG7i8"
   },
   "source": [
    "# Modified version of a function from rahmanidashti/CPFairRecSys: [Official Codes] \n",
    "# CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# by Hossein A. Rahmani.\n",
    "# Modifications: In this function, we have added evaluation of the Gini index for provider and item inventories, \n",
    "# and these evaluations are included in the final results.\n",
    "def write_results():\n",
    "    gini_provider, mean_gini_inventory, individual_ginis = calculate_gini_coefficients(providers)\n",
    "    print(\"mean_gini \",fair_mode,\" provider eps \", provider_eps,\" item eps \", item_eps,\" user eps \", user_eps,':', \n",
    "          \" mean_gini_inventory: \",mean_gini_inventory,\" gini_provider: \",gini_provider)\n",
    "    ndcg_ac, pre_ac, rec_ac, novelty_ac, coverage_ac = metric_per_group(group=active_user_ids, W=W)\n",
    "    ndcg_iac, pre_iac, rec_iac, novelty_iac, coverage_iac = metric_per_group(group=inactive_user_ids, W=W)\n",
    "    ndcg_all, pre_all, rec_all, novelty_all, coverage_all = metric_on_all(W=W)\n",
    "    # print(\"item_group\", item_group[0])\n",
    "    if fair_mode == 'N':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},-,-,-,{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'C':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},{format(user_eps, '.7f')},-,-,{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'I':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},-,{format(item_eps, '.7f')},-,{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'P':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},-,-,{format(provider_eps, '.7f')},{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'CI':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},{format(user_eps, '.7f')},{format(item_eps, '.7f')},-,{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'CP':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},{format(user_eps, '.7f')},-,{format(provider_eps, '.7f')},{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'IP':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},-,{format(item_eps, '.7f')},{format(provider_eps, '.7f')},{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    elif fair_mode == 'CIP':\n",
    "        results.write(\n",
    "            f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},{format(user_eps, '.7f')},{format(item_eps, '.7f')},{format(provider_eps, '.7f')},{gini_provider},{mean_gini_inventory},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{coverage_all},{coverage_ac},{coverage_iac},{item_group[0]},{item_group[1]},{eval_method.total_users * 10}=={item_group[0] + item_group[1]}\")\n",
    "    results.write('\\n')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# New function created by Reza Shafiloo\n",
    "# Function to add an internal item index (iid) to the item metadata\n",
    "\n",
    "def addItemIndex():\n",
    "    itemMeta[\"iid\"] = 0\n",
    "    # print(\"iid_map:\",eval_method.train_set.iid_map)\n",
    "    for index, row in itemMeta.iterrows():\n",
    "        originalId = row[\"IID\"]\n",
    "        itemMeta.at[index, \"iid\"] = eval_method.train_set.iid_map.get(str(originalId), 0)\n",
    "    return 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# New function created by Reza Shafiloo\n",
    "# Function to add a new column with item IDs converted to internal IDs (iids) for provider inventories\n",
    "\n",
    "def add_iid_column():\n",
    "\n",
    "    # Create a dictionary from real world Id to iid for quick lookup\n",
    "    RWID_to_iid = pd.Series(itemMeta['iid'].values, index=itemMeta['IID']).to_dict()\n",
    "\n",
    "    # Function to convert real world Id dictionary to iid-based dictionary\n",
    "    def item_to_iid_converter(item_dict):\n",
    "        iid_dict = {}\n",
    "        for RWID, count in item_dict.items():\n",
    "            # Convert real world Id to iid using the lookup dictionary\n",
    "            iid = RWID_to_iid.get(RWID)\n",
    "            if iid is not None:\n",
    "                iid_dict[iid] = count\n",
    "            else:\n",
    "                print(f\"No iid found for RWID: {RWID}\")\n",
    "        return iid_dict\n",
    "\n",
    "    # Convert the 'itemsAndRatings' column from string to dictionary if necessary and apply conversion\n",
    "    providers_inventory['itemsAndRatings_iid'] = providers_inventory['itemsAndRatings'].apply(\n",
    "        lambda x: item_to_iid_converter(ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    )\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4423d919e0f241edb68988b04f5d69a0",
      "570dd248ee7a45198e7bae5b2a5cd056",
      "5860eb88a52949fcb040e6676ff9d86a",
      "743faee1bf6f45e5b466025a352cabff",
      "c4aa68528dda43a7a95f042990a32e2e",
      "a70686baa50643399420fc10110294c7",
      "3171d1ca6bf44aa5a3050a3fdf377d45",
      "5ca1c72fd22747848f9a4313e9f037b1",
      "1f0a41cccba442ab934cb5092a21e0a0",
      "bc6a1a8b7a7d4bd38e638389d4a990f3",
      "fe7c353218144be88fb20ac5271c99a9",
      "cb9d9b037cde4b07a38d5116f2822a80",
      "ca4462e497e645588209897df98b6f87",
      "220e469f721c46ba9c25dd8b5a3cc40c",
      "8cc16cdf0d9b444692e37bda185baf59",
      "ce5cc0f1a5164034b583eee378e5ed7a",
      "9e2bcefb387d46119c00a2d8cea50d2f",
      "3fc687052c9b469f8f348e00484bfd0b",
      "186e039e08054005af2f49848258c8b0",
      "b834a6fc50ec4b1c85ec167d04a09076",
      "f94aabc1fa2745a3a3cef1e4655b13a8",
      "5a4d64d669fd40a3ad0556ea809975de"
     ]
    },
    "id": "jXev5h4_XGbf",
    "outputId": "38f23948-69c5-4ead-f7d6-d11db400d714"
   },
   "source": [
    "# Modified version of a function from rahmanidashti/CPFairRecSys: [Official Codes] \n",
    "# CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems (SIGIR2022) (github.com) \n",
    "# by Hossein A. Rahmani.\n",
    "# Modifications: \n",
    "# 1. Added a function for integrating providers' inventory into the provider dataset.\n",
    "# 2. Modified the optimizer function to accept modes: ['N', 'C', 'I', 'P', 'CI', 'CP', 'IP', 'CIP'].\n",
    "# 3. Updated providers' inventories after each run for Gini index calculation and then reset inventories \n",
    "#    to their initial state before running the algorithm in different modes to evaluate their impact on provider inventories.\n",
    "\n",
    "# 1: Iterate over the datasets\n",
    "for dataset in ds_names:\n",
    "    print(f\"Datasets: {dataset}\")\n",
    "    # read train, tune, test datasets\n",
    "    train_data, tune_data, test_data = read_data(dataset=dataset)\n",
    "    # load data into Cornac and create eval_method\n",
    "    eval_method = load_data(train_data=train_data, test_data=test_data)\n",
    "    total_users = eval_method.total_users\n",
    "    total_items = eval_method.total_items\n",
    "    # load train_checkins and pop_items dictionary\n",
    "    train_checkins, pop_items = read_train_data(train_file=f\"datasets/{dataset}/{dataset}_train.txt\")\n",
    "    # load ground truth dict\n",
    "    ground_truth = read_ground_truth(test_file=f\"datasets/{dataset}/{dataset}_test.txt\")\n",
    "    # run Cornac models and create experiment object including models' results\n",
    "    exp = run_model(eval_method=eval_method)\n",
    "    # Integrate inventory into the provider dataset\n",
    "    addItemIndex()            \n",
    "    add_iid_column()\n",
    "    Train_List_providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "    providers=copy.deepcopy(Train_List_providers)\n",
    "    # 4: read user groups\n",
    "    for u_group in ds_users:\n",
    "        # read matrix U for users and their groups\n",
    "        U = np.zeros((total_users, no_user_groups))\n",
    "        # load active and inactive users\n",
    "        active_user_ids = read_user_groups(user_group_fpath=f\"user_groups/{dataset}/{u_group}/active_ids.txt\", gid=0)\n",
    "        inactive_user_ids = read_user_groups(user_group_fpath=f\"user_groups/{dataset}/{u_group}/inactive_ids.txt\",\n",
    "                                             gid=1)\n",
    "        print(\n",
    "            f\"ActiveU: {len(active_user_ids)}, InActive: {len(inactive_user_ids)}, All: {len(active_user_ids) + len(inactive_user_ids)}\")\n",
    "        len_sizes = [len(active_user_ids), len(inactive_user_ids)]\n",
    "        # 5: read item groups\n",
    "        for i_group in ds_items:\n",
    "            # read matrix I for items and their groups\n",
    "            I = np.zeros((total_items, no_item_groups))\n",
    "            # read item groups\n",
    "            shorthead_item_ids = read_item_groups(\n",
    "                item_group_fpath=f\"item_groups/{dataset}/{i_group}/shorthead_items.txt\", gid=0)\n",
    "            longtail_item_ids = read_item_groups(item_group_fpath=f\"item_groups/{dataset}/{i_group}/longtail_items.txt\",\n",
    "                                                 gid=1)\n",
    "            print(\n",
    "                f\"No. of Shorthead Items: {len(shorthead_item_ids)} and No. of Longtaill Items: {len(longtail_item_ids)}\")\n",
    "            # 2: iterate over the models\n",
    "            for model in exp.models:\n",
    "                results = open(f\"CIP_results_{dataset}_{model.name}_Dynamic.csv\", 'w')\n",
    "                results.write(\n",
    "                    \"Dataset,Model,GUser,GItem,Type,User_EPS,Item_EPS,Provider_EPS,gini_provider,gini_inventory,ndcg_ALL,ndcg_ACT,ndcg_INACT,Pre_ALL,Pre_ACT,Pre_INACT,Rec_ALL,Rec_ACT,Rec_INACT,Nov_ALL,Nov_ACT,Nov_INACT,Cov_ALL,Cov_ACT,Cov_INACT,Short_Items,Long_Items,All_Items\\n\")\n",
    "                print(f\"> Model: {model.name}\")\n",
    "                # load matrix S and P\n",
    "                S, P = load_ranking_matrices(model=model, total_users=total_users, total_items=total_items,\n",
    "                                                         topk=topk)\n",
    "                \n",
    "                # load matrix Ahelp\n",
    "                Ahelp = load_ground_truth_index(total_users=total_users, topk=topk, P=P, train_checkins=train_checkins)\n",
    "                # load matrix Ihelp\n",
    "                Ihelp = read_item_index(total_users=total_users, topk=50, no_item_groups=no_item_groups)\n",
    "                print(\"Matrix Ihelp:\", Ihelp)\n",
    "                Coeff_list = [0.005, 0.05,0.09, 0.5]\n",
    "                # iterate on fairness mode: Consumers, items, and providers\n",
    "                for fair_mode in ['N', 'C', 'I', 'P', 'CI', 'CP', 'IP', 'CIP']:\n",
    "                    if fair_mode == 'N':\n",
    "                        print(\"N\")\n",
    "                        provider_eps,item_eps,user_eps=0,0,0\n",
    "                        W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode)\n",
    "                        write_results()\n",
    "                        addItemIndex()\n",
    "                        providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'C':\n",
    "                        for user_eps in Coeff_list:\n",
    "                            W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, cepsilon=user_eps)\n",
    "                            write_results()\n",
    "                            add_iid_column()\n",
    "                            providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'I':\n",
    "                        for item_eps in Coeff_list:\n",
    "                            W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, iepsilon=item_eps)\n",
    "                            write_results()\n",
    "                            add_iid_column()\n",
    "                            providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'P':\n",
    "                        for provider_eps in Coeff_list:\n",
    "                            W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, pepsilon=provider_eps)\n",
    "                            write_results()\n",
    "                            add_iid_column()\n",
    "                            providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'CI':\n",
    "                        for user_eps in Coeff_list:\n",
    "                            for item_eps in Coeff_list:\n",
    "                                W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, cepsilon=user_eps,\n",
    "                                                                          iepsilon=item_eps)\n",
    "                                write_results()\n",
    "                                add_iid_column()\n",
    "                                providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'CP':\n",
    "                        for user_eps in Coeff_list:\n",
    "                            for provider_eps in Coeff_list:\n",
    "                                W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, cepsilon=user_eps,\n",
    "                                                                          pepsilon=provider_eps)\n",
    "                                write_results()\n",
    "                                add_iid_column()\n",
    "                                providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'IP':\n",
    "                        for item_eps in Coeff_list:\n",
    "                            for provider_eps in Coeff_list:\n",
    "                                W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, iepsilon=item_eps,\n",
    "                                                                          pepsilon=provider_eps)\n",
    "                                write_results()\n",
    "                                add_iid_column()\n",
    "                                providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                    elif fair_mode == 'CIP':\n",
    "                        for user_eps in Coeff_list:\n",
    "                            for item_eps in Coeff_list:\n",
    "                                for provider_eps in Coeff_list:\n",
    "                                    W, item_group = CIP_Recommendation_optimizer(fairness=fair_mode, cepsilon=user_eps,\n",
    "                                                                              iepsilon=item_eps, pepsilon=provider_eps)\n",
    "                                    write_results()\n",
    "                                    add_iid_column()\n",
    "                                    providers=providers_inventory[\"itemsAndRatings_iid\"].tolist()\n",
    "                results.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "fair_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "186e039e08054005af2f49848258c8b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f0a41cccba442ab934cb5092a21e0a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "220e469f721c46ba9c25dd8b5a3cc40c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_186e039e08054005af2f49848258c8b0",
      "max": 1130,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b834a6fc50ec4b1c85ec167d04a09076",
      "value": 1130
     }
    },
    "3171d1ca6bf44aa5a3050a3fdf377d45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fc687052c9b469f8f348e00484bfd0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4423d919e0f241edb68988b04f5d69a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_570dd248ee7a45198e7bae5b2a5cd056",
       "IPY_MODEL_5860eb88a52949fcb040e6676ff9d86a",
       "IPY_MODEL_743faee1bf6f45e5b466025a352cabff"
      ],
      "layout": "IPY_MODEL_c4aa68528dda43a7a95f042990a32e2e"
     }
    },
    "570dd248ee7a45198e7bae5b2a5cd056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a70686baa50643399420fc10110294c7",
      "placeholder": "​",
      "style": "IPY_MODEL_3171d1ca6bf44aa5a3050a3fdf377d45",
      "value": "100%"
     }
    },
    "5860eb88a52949fcb040e6676ff9d86a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ca1c72fd22747848f9a4313e9f037b1",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f0a41cccba442ab934cb5092a21e0a0",
      "value": 100
     }
    },
    "5a4d64d669fd40a3ad0556ea809975de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ca1c72fd22747848f9a4313e9f037b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "743faee1bf6f45e5b466025a352cabff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc6a1a8b7a7d4bd38e638389d4a990f3",
      "placeholder": "​",
      "style": "IPY_MODEL_fe7c353218144be88fb20ac5271c99a9",
      "value": " 100/100 [00:11&lt;00:00,  8.92it/s, loss=2.63]"
     }
    },
    "8cc16cdf0d9b444692e37bda185baf59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f94aabc1fa2745a3a3cef1e4655b13a8",
      "placeholder": "​",
      "style": "IPY_MODEL_5a4d64d669fd40a3ad0556ea809975de",
      "value": " 1130/1130 [00:02&lt;00:00, 546.35it/s]"
     }
    },
    "9e2bcefb387d46119c00a2d8cea50d2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a70686baa50643399420fc10110294c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b834a6fc50ec4b1c85ec167d04a09076": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc6a1a8b7a7d4bd38e638389d4a990f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4aa68528dda43a7a95f042990a32e2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca4462e497e645588209897df98b6f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e2bcefb387d46119c00a2d8cea50d2f",
      "placeholder": "​",
      "style": "IPY_MODEL_3fc687052c9b469f8f348e00484bfd0b",
      "value": "Ranking: 100%"
     }
    },
    "cb9d9b037cde4b07a38d5116f2822a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca4462e497e645588209897df98b6f87",
       "IPY_MODEL_220e469f721c46ba9c25dd8b5a3cc40c",
       "IPY_MODEL_8cc16cdf0d9b444692e37bda185baf59"
      ],
      "layout": "IPY_MODEL_ce5cc0f1a5164034b583eee378e5ed7a"
     }
    },
    "ce5cc0f1a5164034b583eee378e5ed7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f94aabc1fa2745a3a3cef1e4655b13a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe7c353218144be88fb20ac5271c99a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
